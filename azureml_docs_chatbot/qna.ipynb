{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector = FAISS.load_local(\"./vector-db/\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To define the scoring code for an online endpoint, you need to create an entry script (also known as a scoring script) that will handle the scoring requests. Here's a step-by-step guide on how to set this up:\n",
      "\n",
      "1. **Create a Scoring Script**:\n",
      "    - This script should accept requests, use the model to score the data, and return a response.\n",
      "    - The script typically contains two main functions:\n",
      "        - **init()**: This function is called once when the deployment is initialized. It is used to load the model and any other assets.\n",
      "        - **run(input_data)**: This function is called for each request. It processes the input data and returns the result.\n",
      "\n",
      "    Below is an example of a scoring script (`score.py`):\n",
      "\n",
      "    ```python\n",
      "    import json\n",
      "    import joblib\n",
      "    import numpy as np\n",
      "\n",
      "    def init():\n",
      "        global model\n",
      "        # Load the model from file into a global object\n",
      "        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
      "        model = joblib.load(model_path)\n",
      "        logging.info(\"Model loaded successfully\")\n",
      "\n",
      "    def run(data):\n",
      "        try:\n",
      "            # Parse input data\n",
      "            input_data = json.loads(data)['data']\n",
      "            # Convert input data to numpy array\n",
      "            input_data = np.array(input_data)\n",
      "            # Perform prediction\n",
      "            result = model.predict(input_data)\n",
      "            return json.dumps({\"result\": result.tolist()})\n",
      "        except Exception as e:\n",
      "            error = str(e)\n",
      "            return json.dumps({\"error\": error})\n",
      "    ```\n",
      "\n",
      "2. **Prepare the Environment**:\n",
      "    - Define the dependencies required by the model and the scoring script. This can be done using a Conda environment file.\n",
      "\n",
      "    Example of a Conda environment file (`environment.yml`):\n",
      "\n",
      "    ```yaml\n",
      "    name: myenv\n",
      "    channels:\n",
      "      - defaults\n",
      "    dependencies:\n",
      "      - python=3.8\n",
      "      - scikit-learn\n",
      "      - numpy\n",
      "      - pip\n",
      "      - pip:\n",
      "          - azureml-defaults\n",
      "    ```\n",
      "\n",
      "3. **Specify the Deployment Configuration**:\n",
      "    - Define the deployment configuration, including the model, environment, and scoring script.\n",
      "\n",
      "    Example of a deployment configuration file (`deployment.yml`):\n",
      "\n",
      "    ```yaml\n",
      "    name: mydeployment\n",
      "    endpoint_name: myendpoint\n",
      "    model:\n",
      "      path: model.pkl\n",
      "    environment:\n",
      "      conda_file: environment.yml\n",
      "      image: mcr.microsoft.com/azureml/base:latest\n",
      "    code_configuration:\n",
      "      path: .\n",
      "      scoring_script: score.py\n",
      "    instance_type: Standard_DS2_v2\n",
      "    instance_count: 1\n",
      "    ```\n",
      "\n",
      "4. **Deploy the Model**:\n",
      "    - Use the Azure CLI or SDK to create and deploy the endpoint with the configuration defined.\n",
      "\n",
      "    Example using Azure CLI:\n",
      "\n",
      "    ```bash\n",
      "    az ml online-endpoint create --name myendpoint --file endpoint.yml\n",
      "    az ml online-deployment create --name mydeployment --endpoint myendpoint --file deployment.yml\n",
      "    ```\n",
      "\n",
      "    Example using Python SDK:\n",
      "\n",
      "    ```python\n",
      "    from azure.ai.ml import MLClient\n",
      "    from azure.identity import DefaultAzureCredential\n",
      "\n",
      "    # Connect to your workspace\n",
      "    credential = DefaultAzureCredential()\n",
      "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
      "\n",
      "    # Create the endpoint\n",
      "    endpoint_name = \"myendpoint\"\n",
      "    endpoint = ml_client.online_endpoints.create_or_update(\n",
      "        name=endpoint_name,\n",
      "        compute=\"Managed\",\n",
      "        traffic={\"blue\": 100},\n",
      "    )\n",
      "\n",
      "    # Deploy the model\n",
      "    deployment = ml_client.online_deployments.begin_create_or_update(\n",
      "        name=\"mydeployment\",\n",
      "        endpoint_name=endpoint_name,\n",
      "        model=\"model.pkl\",\n",
      "        environment=\"environment.yml\",\n",
      "        code_configuration={\n",
      "            \"path\": \".\",\n",
      "            \"scoring_script\": \"score.py\"\n",
      "        },\n",
      "        instance_type=\"Standard_DS2_v2\",\n",
      "        instance_count=1\n",
      "    ).result()\n",
      "    ```\n",
      "\n",
      "By following these steps, you define the scoring code and deploy it as an online endpoint in Azure Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "context = [SystemMessage(content=\"You are a helpful AI assistant that can answer user questions about Azure Machine Learning.\")]\n",
    "\n",
    "query = \"How do I define the scoring code for an online endpoint?\"\n",
    "\n",
    "output = retrieval_chain.invoke({\n",
    "    \"context\": context,\n",
    "    \"input\": query\n",
    "})\n",
    "\n",
    "print(output[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
